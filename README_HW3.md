Задача 2. TF-IDF Baseline

1. Recall@1 около 0.363645 — правильный ответ чаще всего не на первом месте, но ключевые слова помогают находить его
Recall@10 около 0.711628 — в топ-10 правильный ответ чаще всего есть
MRR около 0.473967 — в среднем правильный ответ на 2-3 месте

2. Ограничения: TF-IDF не понимает смысл, плохо работает с синонимами и длинными текстами, а вычисления требуют много памяти


Задача 3. E5 Baseline

1. Recall@1 0.693620, 
Recall@10 0.891405, 
MRR 0.798445 — значительно лучше, чем у TF-IDF

2. Модель понимает смысл и контекст, поэтому ищет точнее


Задача 4. E5 Train

1. Дообучение с Contrastive Loss дало хорошие результаты (Recall@1 около 0.56, MRR ~0.67)

2. Triplet Loss показал слабые результаты (Recall@1 около 13%)

Contrastive Loss лучше разделяет правильные и неправильные пары
3. Но дообученные модели пока хуже исходной E5 — возможно из-за случайных негативов и переобучения

