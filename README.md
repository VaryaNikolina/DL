# DL
# Эксперимент 1. Простая модель
# Вывод: Модель улучшает свои результаты по мере обучения. Потери (Train и Test Loss) и ROC-AUC увеличиваются с каждой эпохой, точность улучшается. Улучшения становятся менее заметными после 9-й эпохи, что говорит о стабилизации. Оптимальное количество эпох — 10 или немного меньше, чтобы избежать переобучения.

# Эксперимент 2. Модель побольше
# Вывод: Модель стала лучше: вторая модель имеет более низкие значения потерь и более высокие значения ROC-AUC на обоих наборах данных, особенно в отношении ROC-AUC. Улучшения в обеих сериях заметны, но вторая модель демонстрирует более сильное улучшение, особенно по сравнению с начальными значениями.

# Поведение модели: Модель продолжает улучшать свои показатели с каждой эпохой, но на последних эпохах прирост становится менее заметным, что указывает на стабилизацию

# Эксперимент 3. Skip Connections, Batch Norms
# В целом модель показывает улучшение на тренировочных данных (Train ROC-AUC), но на тестовых данных результаты стабилизировались. Модель на тесте показывает небольшие колебания в ROC-AUC, но в целом остается высокой.

# Модель стабилизировалась в плане улучшения результатов на тестовых данных, но продолжает улучшаться на тренировочных. Это может указывать на небольшое переобучение, так как на тесте не наблюдается значительных улучшений. Обе метрики (Loss и ROC-AUC) показывают стабильные результаты, что говорит о хорошем качестве модели, но стоит внимательно следить за возможным переобучением, если улучшения на тесте будут слабыми в будущем.

# Эксперимент 4. Dropout
# Низкие значения p (например, p = 0.01): Модель склонна к переобучению, что приводит к хорошим результатам на тренировочных данных, но тестовые показатели не улучшаются или даже ухудшаются.

# Средние значения p (например, p = 0.1, p = 0.2): Модель обучается стабильно, достигая хороших результатов как на тренировочных, так и на тестовых данных. Эти значения p обеспечивают баланс между обучением и обобщением.

# Высокие значения p (например, p = 0.9): Модель начинает с низкой производительности, но постепенно улучшается. Однако результаты на старте показывают, что обучение с таким значением p менее стабильное и требует больше времени для достижения хороших показателей.
