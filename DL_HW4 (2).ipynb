{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khVRS_m754XS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Function\n",
        "from typing import Tuple, Any\n",
        "from torch.optim import Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задача 1. RMSNorm"
      ],
      "metadata": {
        "id": "mMcJo08MxLhv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyRMSNorm(nn.Module):\n",
        "    def __init__(self, dim: int, eps: float = 1e-8):\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.gamma = nn.Parameter(torch.ones(dim))  # обучаемый масштаб\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # x: (..., dim)\n",
        "        rms = x.pow(2).mean(dim=-1, keepdim=True).sqrt()  # RMS по последнему измерению\n",
        "        x_norm = x / (rms + self.eps)  # нормализация\n",
        "        return self.gamma * x_norm  # масштабируем"
      ],
      "metadata": {
        "id": "NxjwQ4LBvGIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_rmsnorm():\n",
        "    torch.manual_seed(42)\n",
        "    x = torch.randn(2, 5, 10)  # batch=2, seq_len=5, dim=10\n",
        "\n",
        "    my_norm = MyRMSNorm(dim=10)\n",
        "    torch_norm = nn.RMSNorm(normalized_shape=10)\n",
        "\n",
        "    # синхронизируем веса\n",
        "    with torch.no_grad():\n",
        "        torch_norm.weight.copy_(my_norm.gamma)\n",
        "\n",
        "    out_my = my_norm(x)\n",
        "    out_torch = torch_norm(x)\n",
        "\n",
        "    print(\"Разница (L2 norm):\", (out_my - out_torch).norm().item())\n",
        "    print(\"Совпадают ли:\", torch.allclose(out_my, out_torch, atol=1e-6))"
      ],
      "metadata": {
        "id": "3Efn_RPkvLML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_rmsnorm()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tiCDICMvR0w",
        "outputId": "908c67fc-6a84-4cbe-fa18-591443aea37b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Разница (L2 norm): 1.1754623301385436e-06\n",
            "Совпадают ли: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задача 2. AutoGrad"
      ],
      "metadata": {
        "id": "O0YvRFeDxSRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ExpCosFunction(Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n",
        "        # Сохраняем входы для backward\n",
        "        ctx.save_for_backward(x, y)\n",
        "        return torch.exp(x) + torch.cos(y)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        x, y = ctx.saved_tensors\n",
        "\n",
        "        dx = torch.exp(x) * grad_output       # ∂f/∂x = e^x\n",
        "        dy = -torch.sin(y) * grad_output      # ∂f/∂y = -sin(y)\n",
        "\n",
        "        return dx, dy"
      ],
      "metadata": {
        "id": "slcvF0LJvrCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_exp_cos_autograd():\n",
        "    torch.manual_seed(42)\n",
        "\n",
        "    # Входы\n",
        "    x = torch.randn(4, 5, requires_grad=True)\n",
        "    y = torch.randn(4, 5, requires_grad=True)\n",
        "\n",
        "    # Обычная функция\n",
        "    fx = torch.exp(x) + torch.cos(y)\n",
        "    loss1 = fx.sum()\n",
        "    loss1.backward()\n",
        "    grad_x_ref = x.grad.clone()\n",
        "    grad_y_ref = y.grad.clone()\n",
        "\n",
        "    # Обнуляем градиенты\n",
        "    x.grad.zero_()\n",
        "    y.grad.zero_()\n",
        "\n",
        "    # Кастомная функция\n",
        "    fx_custom = ExpCosFunction.apply(x, y)\n",
        "    loss2 = fx_custom.sum()\n",
        "    loss2.backward()\n",
        "    grad_x_custom = x.grad\n",
        "    grad_y_custom = y.grad\n",
        "\n",
        "    # Проверки\n",
        "    print(\"dx совпадает:\", torch.allclose(grad_x_ref, grad_x_custom, atol=1e-6))\n",
        "    print(\"dy совпадает:\", torch.allclose(grad_y_ref, grad_y_custom, atol=1e-6))\n",
        "    print(\"Разница L2 (dx):\", (grad_x_ref - grad_x_custom).norm().item())\n",
        "    print(\"Разница L2 (dy):\", (grad_y_ref - grad_y_custom).norm().item())"
      ],
      "metadata": {
        "id": "1LUOZ9mdwAsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_exp_cos_autograd()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7jkKXe19wIFL",
        "outputId": "48cc75e3-e9c8-405c-e29b-5e282c9f1a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dx совпадает: True\n",
            "dy совпадает: True\n",
            "Разница L2 (dx): 0.0\n",
            "Разница L2 (dy): 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задача 3. Lion"
      ],
      "metadata": {
        "id": "Mgk-aJKdxYUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Lion(Optimizer):\n",
        "    def __init__(\n",
        "        self,\n",
        "        params,\n",
        "        lr=1e-3,\n",
        "        betas=(0.9, 0.99),\n",
        "        weight_decay=0.0,\n",
        "    ):\n",
        "        defaults = dict(lr=lr, betas=betas, weight_decay=weight_decay)\n",
        "        super(Lion, self).__init__(params, defaults)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self, closure=None):\n",
        "        for group in self.param_groups:\n",
        "            lr = group['lr']\n",
        "            beta1, beta2 = group['betas']\n",
        "            weight_decay = group['weight_decay']\n",
        "\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "\n",
        "                grad = p.grad.data\n",
        "                state = self.state[p]\n",
        "\n",
        "                if 'exp_avg' not in state:\n",
        "                    state['exp_avg'] = torch.zeros_like(p.data)\n",
        "\n",
        "                exp_avg = state['exp_avg']\n",
        "\n",
        "                update = (1 - beta1) * grad + beta1 * exp_avg\n",
        "                update = torch.sign(update)\n",
        "\n",
        "                if weight_decay != 0:\n",
        "                    update = update + weight_decay * p.data\n",
        "\n",
        "                p.data.add_(update, alpha=-lr)\n",
        "\n",
        "                exp_avg.mul_(beta2).add_(grad, alpha=1 - beta2)"
      ],
      "metadata": {
        "id": "4oot5jVFwIkW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_lion_optimizer():\n",
        "    torch.manual_seed(0)\n",
        "\n",
        "    model = nn.Sequential(\n",
        "        nn.Linear(10, 1)\n",
        "    ).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    x = torch.randn(100, 10).to(model[0].weight.device)\n",
        "    y = torch.randn(100, 1).to(model[0].weight.device)\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = Lion(model.parameters(), lr=1e-3)\n",
        "\n",
        "    for epoch in range(100):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(x)\n",
        "        loss = criterion(output, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch {epoch} | Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "id": "YgxNNgtNwie3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_lion_optimizer()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUnY0HJFwmhC",
        "outputId": "7daa83ac-08b4-42cf-8c6f-45e2ecd84cdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | Loss: 1.0317\n",
            "Epoch 10 | Loss: 1.0078\n",
            "Epoch 20 | Loss: 0.9856\n",
            "Epoch 30 | Loss: 0.9651\n",
            "Epoch 40 | Loss: 0.9463\n",
            "Epoch 50 | Loss: 0.9291\n",
            "Epoch 60 | Loss: 0.9135\n",
            "Epoch 70 | Loss: 0.8997\n",
            "Epoch 80 | Loss: 0.8875\n",
            "Epoch 90 | Loss: 0.8770\n"
          ]
        }
      ]
    }
  ]
}